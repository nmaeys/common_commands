 ____        _   _                 
|  _ \ _   _| |_| |__   ___  _ __  
| |_) | | | | __| '_ \ / _ \| '_ \ 
|  __/| |_| | |_| | | | (_) | | | |
|_|    \__, |\__|_| |_|\___/|_| |_|
       |___/                       
By Nick Tomasino

[[ DATA_STRUCTURES ]]
    all data structure examples are from: https://docs.python.org/2/tutorial/datastructures.html

    [[ LISTS ]]
        Count method tells you how many times an element appears in a list
        has a sort method. you can override the key it compares on 
        >>> l = ['a','b','c']
        >>> l.append('c')                                                                                                       
        >>> l                                                                                                                   
        ['a', 'b', 'c', 'c'] 
        >>> l.count('c')                                                                                                        
        2 

        #help tells us the methods of an object
        >>> help(l)

        Can use like a stack via append/pop
        >>> l.pop()                                                                                                             
        'c'                                                                                                                     
        >>> l                                                                                                                   
        ['a', 'b', 'c']

        Or a queue with pop(0)
        ['a', 'b', 'c', 'd']                                                                                                    
        >>> l.pop(0)                                                                                                            
        'a'                                                                                                                     

        [[ FUNCTIONAL TOOLS ]]
            map, reduce, filter
            https://docs.python.org/2/tutorial/datastructures.html#functional-programming-tools

    [[ SETS ]]
        Python also includes a data type for sets. A set is an unordered collection with 
        no duplicate elements. Basic uses include membership testing and eliminating duplicate entries. 
        Set objects also support mathematical operations like union, intersection, difference, 
        and symmetric difference.

        >>> # Demonstrate set operations on unique letters from two words
        ...
        >>> a = set('abracadabra')
        >>> b = set('alacazam')
        >>> a                                  # unique letters in a
        set(['a', 'r', 'b', 'c', 'd'])
        >>> a - b                              # letters in a but not in b
        set(['r', 'd', 'b'])
        >>> a | b                              # letters in either a or b
        set(['a', 'c', 'r', 'd', 'b', 'm', 'z', 'l'])
        >>> a & b                              # letters in both a and b
        set(['a', 'c'])
        >>> a ^ b                              # letters in a or b but not both
        set(['r', 'd', 'b', 'm', 'z', 'l'])

    [[ DICTIONARIES ]]
        It is best to think of a dictionary as an unordered set of key: value pairs, 
        with the requirement that the keys are unique
        item is the (key : value)
        >>> tel = {'jack': 4098, 'sape': 4139}
        >>> tel['guido'] = 4127
        >>> tel
        {'sape': 4139, 'guido': 4127, 'jack': 4098}
        >>> tel.items()                                                                                                         
        [('sape', 4139), ('jack', 4098), ('guido', 4127)]                                                                       
        >>> tel.keys()                                                                                                          
        ['sape', 'jack', 'guido']                                                                                               
        >>> tel.values()                                                                                                        
        [4139, 4098, 4127]  
        
    [[ STRATEGY_PATTERN ]]
        strat = {
                True    : 'case1',
                False   : 'case2',
                }

        >>> [strat[i] for i in .5 < np.random.rand(10)]
        ['case1', 'case2', 'case2', 'case1', 'case1', 'case1', 'case1', 'case1', 'case2', 'case2']

    [[ DICTIONARY_EXERCISE ]]
        Code FizzBuzz using a strategy pattern

[[ LIST_COMPREHENSIONS ]]
    "yoda talk" 
    [<what you wanna do> <what you're iterating over> <condition>]

    >>> [i**2 for i in range(10) if i > 5]                                                                                  
    [36, 49, 64, 81]

    from: https://docs.python.org/2/tutorial/datastructures.html#list-comprehensions
    >>> [(x, y) for x in [1,2,3] for y in [3,1,4] if x != y]
    [(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]

    >>> # flatten a list using a listcomp with two 'for'
    >>> vec = [[1,2,3], [4,5,6], [7,8,9]]
    >>> [num for elem in vec for num in elem]
    [1, 2, 3, 4, 5, 6, 7, 8, 9]

[[ GENERATOR_EXPRESSIONS ]]
    similar to list comprehensions but are lazy

    for an example of more generalized generators see:
    http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html#example-generator

[[ BUILT_IN_FUNCTIONS ]]
    https://docs.python.org/2/library/functions.html
    zip (see also itertools' izip) - combine two lists together into a list of tuples
        >>> x = [1,2,3] 
        >>> y = [4,5,6] 
        >>> zip(x,y) 
        [(1, 4), (2, 5), (3, 6)]

    xrange - yields the same values as the corresponding list, without actually storing them all simultaneously
    sum
    round
    sorted
    any, all
    del 
    open - open a file
    
[[ ITERTOOLS ]]
    https://docs.python.org/2/library/itertools.html

    import itertools as it
    Note: These functions return GENERATOR_EXPRESSIONS, cast them as a list to see what's inside
    i.e. 
    g = it.product('ABCD', repeat=2)
    list(g)

    product('ABCD', repeat=2)                       AA AB AC AD BA BB BC BD CA CB CC CD DA DB DC DD
    permutations('ABCD', 2)                         AB AC AD BA BC BD CA CB CD DA DB DC
    combinations('ABCD', 2)                         AB AC AD BC BD CD
    combinations_with_replacement('ABCD', 2)	 	AA AB AC AD BB BC BD CC CD DD

    groupby:  https://docs.python.org/2/library/itertools.html#itertools.groupby
    compress: https://docs.python.org/2/library/itertools.html#itertools.compress
    
    [[ ITERTOOLS_EXERCISE ]]
        1. Generate an 8x8 grid of points. Display it using matplotlib.pyplot's scatter function.
            Hint: you may need to use pyplot.show()
            import matplotlib.pyplot as plt

        2. Create a list of all of the 3 letter combinations of the letters A through F, 
            group them by their second letter, and then assign each element a 50% chance of being compressed.
            Hint: must have sorted data for groupby!

[[ PARSING ]]

    [[ STRIPPING ]]
        strip - removes whitespace from the beginning/end of strings
        lstrip - remove leading whitespace
        rstrip - remove trailing whitespace

        example code
        my_string = "blah, lots  ,  of ,  spaces, here "
        [x.strip() for x in my_string.split(',')]

    [[ SPLITTING ]]
        >>> string = ' first, second, third '                                                                                   
        >>> string                                                                                                              
        ' first, second, third '                                                                                                
        >>> string.strip()                                                                                                      
        'first, second, third'                                                                                                  
        >>> string.rstrip()                                                                                                     
        ' first, second, third'                                                                                                 
        >>> string.lstrip()                                                                                                     
        'first, second, third ' 
        >>>[i.strip() for i in string.split(',')]                                                                              
        ['first', 'second', 'third']
        things to split on: \t, \n or \r or \r\n, 

    [[ SLICING ]]
        usually you just use [start:stop]
        but you can specify a step or value to increment by: [start:stop:increment]
        you can leave out start or stop too, meaning 'everything up until the nth position' or
        everything after the nth position:
        [:n] or [n:]

        Example Code
        >>> array = string.split(',')
        >>> array
        ['first', ' second', ' third']
        >>> array[:2]
        ['first', ' second']
        >>> array[0:3:1]
        ['first', ' second', ' third']
        >>> array[0:3:2]
        ['first', ' third']

        links:
        https://pythonhosted.org/bitstring/slicing.html

    [[ JOINING ]]
        join an array together with the delimiter char(s) you specify

        >>> array 
        ['first', 'second', 'third']

        >>> ",".join(array)
        'first,second,third'

        >>> print '\n'.join(array)
        first
        second
        third

    [[ REGULAR_EXPRESSIONS ]]
        See ./regex_class.txt
        https://docs.python.org/2/library/re.html
        import re
        re.search(pattern, file)
        re.search(pattern, file).group(groupnumber)

        from: https://docs.python.org/2/howto/regex.html
        p = re.compile('\d+')
        p.findall('12 drummers drumming, 11 pipers piping, 10 lords a-leaping')
        ['12', '11', '10']

        https://automatetheboringstuff.com/chapter7/

[[ FILE_IO ]]
    first method: with open (context manager)
    with open('filename.txt', file_mode) as filename:
        for line in filename.readlines():
            <process line>

    second method: file function
    f = file('filename.txt', filemode)
    f.close() #DON'T FORGET TO CLOSE THE FILE

    links:
    description of file modes from..
    http://www.tutorialspoint.com/python/python_files_io.htm
    r	Opens a file for reading only. The file pointer is placed at the beginning of the file. This is the default mode.
    rb	Opens a file for reading only in binary format. The file pointer is placed at the beginning of the file. This is the default mode.
    r+	Opens a file for both reading and writing. The file pointer placed at the beginning of the file.
    rb+	Opens a file for both reading and writing in binary format. The file pointer placed at the beginning of the file.
    w	Opens a file for writing only. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.
    wb	Opens a file for writing only in binary format. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.
    w+	Opens a file for both writing and reading. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.

    http://www.codecademy.com/courses/python-intermediate-en-OGNHh/0/1

[[ CSV_FILES ]]
    import csv
    csv_file = csv.reader(file, delimiter = ',')
    for row in csv_file:
        row[fieldnumber]

    See examples/extract.py for an example

    [[ FILE_EXERCICES ]]
        Use examples/head-wa.csv
        1.Read in a file in and print out each line beginning with the line number and a tab.
            1   line1
            2   line2
            ...
        2.Read in the examples/encoded_message.txt file in binary mode and print out each byte after incrementing it by one.
        3.Read in a csv file and print out the first, third, and fourth fields delimited by tabs instead of commas
            i.e. take a file of format:     field1, field2, field3, field4
            and change it too:              field1    field3

    [[ PARSING_EXCERCISES ]]
        1. Increment the year of the dates in examples/head-wa.txt, join the dates back together with dashes instead of slashes
        2. Using examples/extract_pandas.csv, column Offense_Type, print out a list of all of the offense types where 
            each offense occurs no more than once. (Hint: Think back to DATA_STRUCTURES)
            Bonus: print out the nuber of times each crime occurs.
        3. Repeat #2 on the Premise field of examples/extract_pandas.csv
        4. Using the file examples/extract_pandas.csv and the Premise column: Make a list of unique phrases between parentheses

[[ DEBUGGING ]]
    most GUI IDE's will have a built-in debugger of some sort
    (pdb, or pydbgr, and ipdb are also available.)
    pudb - best command line tracing program. 
        sudo pip install pudb

    [[ DEBUGING_EXERCISE ]]
        Download and install pudb 
        Use pudb to set breakpoints in a program, step through the code, while examining certain varibles

[[ SPECIAL_TOPICS ]]

[[ COMMAND_LINE_INTERFACING ]]
    import argparse
    parser = argparse.ArgumentParser(description=discription_message)
    parser.add_argument("-f", "--file", required=True, dest="input_file", help="file to import")
    parser.add_argument("-m", "--max_percentage", dest="max_percentage", type=float, default=.6, help="drop rows with..")
    args = parser.parse_args()
    args.input_file #now contains the file supplied at runtime

[[ CLI_EXCERCISE ]]
    Design a simple program that accepts command line arguements for a file to read in, which lines to print 
    and whether or not to add line numbers to the front of it.

[[ HTML_PARSING ]]
    [[ pyquery ]]

    [[ beautiful_soup ]]
        https://automatetheboringstuff.com/chapter11/
        beautiful soup examples

    [[ HTML_EXERCISES ]]
        Scrape a web page and parse out particular fields of interest. Craigslist is a good one to start with.

[[ NUMPY ]]
#Generate random sequences
>>> np.random.rand(3,2)
array([[ 0.78782888,  0.13322582],
       [ 0.05043413,  0.16699798],
       [ 0.68784864,  0.45938167]])

[[ PANDAS ]]
    [[ READ_CSV ]]
        d=pd.read_csv(input_file, thousands=',', sep=',')
        d.columns = ['col1','col2','col3','col4']

    [[ EXCEL_WRITING ]]
        writer = pd.ExcelWriter('output.xlsx', engine='xlsxwriter')
        df_out.transpose().to_excel(writer,'Sheet1')
        writer.save()

    [[ CLEANUP ]]
        #delete all rows whose col1 value is 0
        df = df[df.col1 != 0]

        #delete a column
        del df[col1]

        #drop all null values (if ANY column in a row has a null in it, the entire row get's dropped)
        df.dropna()

        #drop rows with nulls in a column
        df = df.dropna(subset=['col_with_nulls'])

        #drop duplicate entries in specified cols
        df = df.drop_duplicates(subset=['col1', 'col2'], take_last=False, inplace=False)

    [[ INPUT_DATA_VALIDATION ]]
        #if all data in a frame isn't numeric, it this will catch the error, then iterate through all columns
        def validate_data(df):
            try:
                all(np.isfinite(df))
            except TypeError:
                for c in df.columns:    
                    try:
                            print c
                            print all(np.isfinite(df[c]))
                    except TypeError:
                        print 'Error with column: '+c+'\nIt must be composed of all numbers.'
                sys.exit(2)

    [[ TYPE_CONVERSION ]]
        df[['two', 'three']] = df[['two', 'three']].astype(float)

    [[ MERGING ]]
        http://pandas.pydata.org/pandas-docs/stable/merging.html
            df_merged = pd.merge(df_left, df_right, how=(left,right,inner,outer),\
                left_on=left_column, right_on=right_column,\
                suffixes=('_l','_r'))


    [[ COLUMN_TRANFORM ]]
        Apply a function to each row in dataframe using map and lamdas
        d.column1.map(
            lambda x: x+1
        )

    [[ COLUMN_MERGING ]]
        #join multiple columns into the same column
        d['Address'] = pd.DataFrame([' '.join([str(i[0]),i[1],i[2]]) for i in zip(d.BlockRange, d.StreetName, d.Type)], index=d.index)

    [[ PIVOT ]]
        #MULTI_INDEX
        d.set_index(['group','Demographics'], inplace=True)
        
        #GROUPBY SINGLE_INDEX from groupby operation
        df.groupby(by = ['Created By']).sum().head()

        #GROUPBY MULTI_INDEX Create a MULTI_INDEX from a groupby operation
        df['Created Date'] = pd.to_datetime(df['Created Date'], format = '%m/%d/%Y')
        groups = df.groupby(by = ['Created By', pd.TimeGrouper(freq='M', key='Created Date')]).sum()

        #CROSSTAB - regroup dataframe into a new format
        pd.crosstab(index = df['Created By'],
            columns = df['Created Date'],
            values = df['Amount'],
            aggfunc = np.sum )

        #MELT and PIVOT TABLE example (see pivot examples/pivot_salesman.py)
        df['Created Date'] = pd.to_datetime(df['Created Date'], format = '%m/%d/%Y')
        melted = pd.melt(df, id_vars = ['Created Date', 'Created By'], value_vars = ['Amount', 'opp_count'])
        final = melted.pivot_table(
                       index = 'Created By',
                       columns = [pd.TimeGrouper('M', key = 'Created Date'), 'variable'],
                       aggfunc = np.sum,
                       values = 'value'
                )

    [[ PANDAS_EXERCISES ]]
        [[ INPUT_DATA_VALIDATION_EXERCISE ]]
            1. Create a data frame of random data (Hint, leverage numpy)
            2. Replace some numeric fields in the frame with strings
            3. Run the INPUT_DATA_VALIDATION

        [[ MERGE_EXERCISE ]]
            1. Join two data frames together on an comparable columns. 
            You can Join jan15 and extract_pandas.csv on date for this exercise
        
        [[ COLUMN_TRANFORM_EXERCISE ]]
            1. Square each number in a column
            2. Read in excercises/jan15.csv and replace the BlockRange column with the mean of the range
            3. Redo PARSING_EXCERCISES exercise 1 using pandas column transforms(included below for convenience)
                Increment the year of the dates in examples/head-wa.txt, join the dates back together with dashes instead of slashes

        [[ PIVOT_EXERCISE ]]
            Mess around with pivot_salesman.py in examples

[[ MATPLOTLIB ]]
http://pandas.pydata.org/pandas-docs/version/0.15.0/visualization.html

#Will show matplots if you're seeing something like: <matplotlib.axes.AxesSubplot object at 0x109c8ef50>
>>> import matplotlib.pyplot as plt
>>> plt.show()
